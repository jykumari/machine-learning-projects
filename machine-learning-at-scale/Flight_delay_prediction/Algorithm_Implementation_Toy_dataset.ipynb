{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "683d4c13-182d-4f4c-93de-0d6d7833a480",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Toy dataset - Algorithm Implementation\n",
    "\n",
    "**This notebook is to demonstrate algorithm implementation with toy dataset.**\n",
    "\n",
    "As part of this Algorithm implementation, we created our own toy example that matches the dataset provided and used this toy example to explain the math behind the logistic regression and finding the loss through gradient descent. This algorithm has been applied to the training dataset and has been evaluated on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a7aeb2f-4fb3-4f9b-bb04-a8b1b9514a13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Section 1 - Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "860d1e18-8843-40ec-9b06-baca76a0b902",
     "showTitle": true,
     "title": "Import Libraries"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from html import escape\n",
    "from IPython.display import HTML, display as ipython_display\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import IntegerType, StringType, BooleanType, DateType, DoubleType\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c1eb45d1-01f5-4e23-9333-2ccc83e93020",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Set Up Blob Storage\n",
    "\n",
    "blob_container = \"w261-container\" # The name of your container created in https://portal.azure.com\n",
    "storage_account = \"w261storageaccount\" # The name of your Storage account created in https://portal.azure.com\n",
    "secret_scope = \"w261scope\" # The name of the scope created in your local computer using the Databricks CLI\n",
    "secret_key = \"w261key\" # The name of the secret key created in your local computer using the Databricks CLI \n",
    "blob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\"\n",
    "mount_path = \"/mnt/mids-w261\"\n",
    "\n",
    "spark.conf.set(\n",
    "  f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n",
    "  dbutils.secrets.get(scope = secret_scope, key = secret_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "07b0255e-e260-4bda-abf0-cde41d8173b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Section 2 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f0577420-3f78-4b83-a044-a0b8f32f33f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read joined dataset from parquet.\n",
    "\n",
    "# Take a small sample 0.01% of the Train and Test Datasets to create the Toy Example\n",
    "\n",
    "toy_train = spark.read.parquet(f\"{blob_url}/model_train_data_full_v2/*\")\n",
    "toy_test = spark.read.parquet(f\"{blob_url}/model_test_data_full_v2/*\")\n",
    "                      \n",
    "toy_train = toy_train.select('departure_delay_boolean', 'VectorAssembler_features')\n",
    "toy_test = toy_test.select('departure_delay_boolean', 'VectorAssembler_features')\n",
    "\n",
    "toy_train = toy_train.sample(0.0001, 3)\n",
    "toy_test = toy_test.sample(0.0001, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fc838099-193d-44bd-a435-4cf2932f01bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Section 3 - Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "745bb5b0-8e6a-48b8-b7e4-6267932d63c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper function\n",
    "# Create helper function to print evaluation metrics\n",
    "\n",
    "def print_results(predictions):\n",
    "  tp = predictions[(predictions.label == 1) & (predictions.prediction == 1)].count()\n",
    "  tn = predictions[(predictions.label == 0) & (predictions.prediction == 0)].count()\n",
    "  fp = predictions[(predictions.label == 0) & (predictions.prediction == 1)].count()\n",
    "  fn = predictions[(predictions.label == 1) & (predictions.prediction == 0)].count()\n",
    "  total = predictions.count()\n",
    "  \n",
    "  recall = float(tp)/(tp+fn)\n",
    "  precision = float(tp)/(tp+fp)\n",
    "  f1 = (2*recall*precision)/(precision+recall)\n",
    "  \n",
    "  data = {'Actual-delay': [tp, fn], 'Actual-on time': [fp, tn]}\n",
    "  confusion_matrix = pd.DataFrame.from_dict(data, orient='index', columns=['Predicted-delay', 'Predicted-on time'])\n",
    "  \n",
    "  #print(\"Test Area Under ROC: \", \"{:.2f}\".format(evaluator.evaluate(predictions, {evaluator.metricName: 'areaUnderROC'})))\n",
    "  #print(\"Test Area Under Precision-Recall Curve: \", \"{:.2f}\".format(evaluator.evaluate(predictions, {evaluator.metricName: 'areaUnderPR'})))\n",
    "\n",
    "  print(\"Sensitivity: {:.2%}\".format(tp/(tp + fn)))\n",
    "  print(\"Specificity: {:.2%}\".format(tn/(tn + fp)))\n",
    "  print(\"False positive rate: {:.2%}\".format(fp/(fp + tn)))\n",
    "  print(\"False negative rate: {:.2%}\".format(fn/(tp + fn)))\n",
    "  print(\"Recall: {:.2%}\".format(recall))\n",
    "  print(\"Precision: {:.2%}\".format(precision))\n",
    "  print(\"f1: {:.2%}\".format(f1))\n",
    "  \n",
    "  print(\"########### Confusion Matrix ###########\")\n",
    "  print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a20ed206-7907-4036-9352-062e1b2eb872",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Section 4 - Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "be888ed5-d39c-426b-a147-a53340f3e1a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Logistic regression aggregates the predictor variables similar to Linear Regression. The input \\\\(X_j\\\\) is multiplied by a weight \\\\(beta_j\\\\) and the product \\\\(X_j \\beta_j\\\\) is added as shown below:  \n",
    "\n",
    "$$\\displaystyle f(X)= \\beta_0 + \\Sigma_{j=1}^p X_j \\beta_j$$\n",
    "\n",
    "This can be expressed as \\\\(f(X)= \\theta^TX\\\\) in matrix form, where \\\\(\\theta\\\\) is a vector of weights including beta_0 \\\\( \\beta_0 \\\\), and \\\\(X\\\\) is a vector of inputs (with an input of \\\\(0\\\\) for \\\\(\\beta_0\\\\). Logistic regression embeds the output of \\\\(\\theta^TX\\\\) in a new funtion \\\\(g(z)\\\\) where $$\\displaystyle g(z)=\\frac{1}{1+e^{-z}}$$ \n",
    "\n",
    "This can be expressed as: $$h_\\theta (x) = g(\\theta^Tx)$$ where \\\\(g(z)=\\frac{1}{1+e^{-z}}\\\\) \\\\(g(z)\\\\) is a sigmoid function, and it scales all outputs values to between 0 and 1. By substituting \\\\(\\theta^TX\\\\) for \\\\(z\\\\), the simplified equation is as follows: \n",
    "\n",
    "$$\\displaystyle h_\\theta (x) = \\frac{1}{1+e^{-\\theta^TX}}$$ \n",
    "\n",
    "The value $$h_\\theta(x)$$ is the probability estimate that \\\\(x\\\\) is a member of category \\\\(y=1\\\\) The probability that \\\\(y=0\\\\) will then be $$1 - h_\\theta(x)$$ \\\\(h_\\theta(x)\\\\) ranges from 0 to 1 due to the application of the sigmoid function and both probabilities will add to one.\n",
    "\n",
    "The cost or loss function computes the error of the model. The weights used in logistic regression equation can vary from one model to another. The goal of a model is to fit the data that minimizes the cost function. Comparison of model performance can be done by calculating the error of the models when attempting to predict label \\\\(y\\\\).   \n",
    "\n",
    "For logistic regression, the squared loss function is not convex and has many local minima and alternatives like hinge loss and logistic loss function is used. \n",
    "For logistic loss, the negative log of the logistic regression output is taken when the actual value of \\\\(y\\\\) is 1. When the actual value of \\\\(y\\\\) is 0, the negative log of 1 minus the logistic regression output is used. \n",
    "\n",
    "This can be expressed as:\n",
    "<br>\n",
    "<img src ='https://sudhritybucket.s3.amazonaws.com/cf1.png' width=\"400\" height=\"400\">\n",
    "<br>\n",
    "\n",
    "When the logistic regression predicts \\\\(\\hat{y}=1\\\\) with a probability of 1 correctly, then \\\\(-log(1)=0\\\\) and the loss function is zero, this is a perfect prediction. Similarly, when \\\\(\\hat{y}:0\\\\) is correctly predicted with a probability of 1, the cost function will be \\\\(-log(1-1)=0\\\\). For an incorrect prediction of \\\\(P(\\hat{y}:0)=.999\\\\), (and the corresponding probability \\\\(P(\\hat{y}:1)=.001)\\\\) but \\\\(y=1\\\\), then the log loss function will be \\\\(-log(.001)\\approx3\\\\) showing a higher amount of error. Since we can't take the log of 0, values of .999 and .001 are used. As the correct prediction approaches a probability of 0, the log loss function will approach infinity and the prediction is \\\\(y=0\\\\)\n",
    "\n",
    "The weights in logistic regression can be selected at random, and the cost function can be evaluated to see if the new model is an improvement over the last but this is inefficient. The cost function has a slope of zero at its minimum and taking a derivative of the cost function to obtain the slope, and then moving to the next iteration closer to zero, we can find a minimum of the cost function. However, we have to make sure that we are moving in the right direction to find a minimum, since the derivative of the maximum of the cost function will also have a slope of zero. Several different algorithms including Gradient Descent, Newton methods, and quasi-Newton methods can be used that apply some variation of this approach.\n",
    "\n",
    "In Gradient Descent, the first-order derivative of the cost function is evaluated which provides the slope or gradient. The next step is taken based on the greatest negative change in gradient. The learning rate or the step-size is constant for each step and is set by the user. With multiple iterations, the minimum is reached. We will use this method in our toy logistic regression implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7bac5414-e19d-43d7-b0cc-3e6460207764",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn sampled Dataframes into RDDs for processing into feature array, label format\n",
    "\n",
    "trainRDD = toy_train.rdd.map(lambda x: (x[1:],x[0])).cache()\n",
    "testRDD = toy_test.rdd.map(lambda x: (x[1:],x[0])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bde2b1e0-84ab-489e-ade3-70a25b4d67af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As it was discussed above Logistic regression uses the sigmoid function to solve classification problems\n",
    "\n",
    "Using the sigmoid function $$h_\\theta (x) = \\frac{1}{1+e^{-\\theta^TX}}$$\n",
    "\n",
    "Where the cost function is given by:\n",
    "\n",
    "$$ cost(h_{\\theta}(x),y)=-y^i \\times \\log(h_\\theta (x^{i})) - (1-y^i) \\times \\log(h_\\theta (x^i))$$\n",
    "\n",
    "Therefore, the loss function for logistic regression, when dealing with a vector of n parameters, is defined as it follows: \n",
    "\n",
    "$$ J(\\theta)=\\frac{1}{n}\\sum_{i=1}^{n}\\left(x^i\\times\\log(h_\\theta (x^i))+(1-y^i)\\times\\log(h_\\theta (x^i))\\right)$$\n",
    "\n",
    "Which is translated in the below equation as **loss variable (line 15)**, which is inside of our LogLoss function. With the only variation that we are leveraging the use mean of the function instead of dividing it to increase the efficiency of the RDD calculation. \n",
    "\n",
    "It is important to point put we are augmenting our data using a bias at index 0.\n",
    "\n",
    "**Where in the RDD implementation x[0] is equivalent to the feature array or x and x[1] is y in the formulas above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "119b10db-3ea9-4c1d-ba5b-f00ddd96eef8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "  \n",
    "def LogLoss(dataRDD, W): \n",
    "    \"\"\"\n",
    "    Compute logistic loss error.\n",
    "    \n",
    "    Where:\n",
    "        dataRDD - each record is a tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Augment the data by adding 1 to the front of the predictors array\n",
    "    \n",
    "    augmented_data = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "    \n",
    "    # Calculate loss\n",
    "    \n",
    "    loss = augmented_data.map(lambda x: x[1] * np.log(sigmoid(W.dot(x[0]))) + (1-x[1]) * np.log(sigmoid(W.dot(x[0])))).mean()*-1\n",
    "   \n",
    "    return loss\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "24bbf21a-f46c-4c7a-950a-b5241d8b8270",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In gradient descent we aim to find the minimum of a  differentiable function trying different values an updating them to reach the optimal levels. Thus, minimizing the differentiable function. \n",
    "\n",
    "$$\\theta_j \\leftarrow \\theta_j - \\alpha \\frac{\\partial}{\\partial\\theta_j}J(\\theta)$$\n",
    "\n",
    "In order to minimize the function we need to run the gradient descent on each parameter of the weight vector (W).\n",
    "\n",
    "Assume we have a total of n features. In this case, we have n parameters for the weight vector vector. To minimize our cost function, we need to run the gradient descent on each parameter of the W  vector.\n",
    "\n",
    "In order to use gradient descent we need to calculate the derivative of the function:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n}\\left((h_\\theta)x^i-y^i \\right)x^i_j$$\n",
    "\n",
    "It is important to point out that we are using ridge (L2) regularization to increase the generalizability of our model. Thefore we need to add the term for the penalty (without including the Bias term) which is:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n}\\left((h_\\theta)x^i-y^i x^i_j + \\lambda x \\right)$$\n",
    "\n",
    "\n",
    "And then updating using the learning rate parameter in the previous equation, which provides the new model for this iteration.\n",
    "\n",
    "$$\\theta_j \\leftarrow \\theta_j - \\alpha \\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n}\\left((h_\\theta)x^i-y^i x^i_j + \\lambda x \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2b141171-5dbf-44bf-9c0d-7f3c4ef26849",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def GDUpdate_wReg(dataRDD, W, learning_rate = 0.1, reg_param = 0.1):\n",
    "    \"\"\"\n",
    "    Gradient descent update with ridge regularization (1 Iteration).\n",
    "    \"\"\"\n",
    "    \n",
    "    W_broadcast = sc.broadcast(W)\n",
    "    \n",
    "    new_model = None\n",
    "    \n",
    "    N = dataRDD.count()\n",
    "    \n",
    "    augmented_data = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "\n",
    "    grad = augmented_data.map(lambda x: ((sigmoid(W.dot(x[0])) - x[1])*x[0])).sum()\n",
    "    \n",
    "    ### Add regularization penalty\n",
    "    \n",
    "    grad += reg_param * np.append([0.0], W[1:])\n",
    "    \n",
    "    new_model = W - learning_rate * grad / N\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d4f7c72d-01f5-4ac7-b39b-eaea5a311c49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def GradientDescent_wReg(trainRDD, testRDD, wInit, nSteps = 10, learning_rate = 0.1 , reg_param = 0.1):\n",
    "    \"\"\"\n",
    "    Loops gradient descent regularization based on steps and creates/updates lists with loss results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize list to store values\n",
    "    \n",
    "    train_history, test_history, model_history = [], [], []\n",
    "    \n",
    "    # perform iterations and calculate loss\n",
    "    \n",
    "    model = wInit\n",
    "    for idx in range(nSteps): \n",
    "      \n",
    "        # update the model\n",
    "        model = GDUpdate_wReg(trainRDD, model, learning_rate, reg_param)\n",
    "        \n",
    "        # append results\n",
    "        train_history.append(LogLoss(trainRDD, model))\n",
    "        test_history.append(LogLoss(testRDD, model))\n",
    "        model_history.append(model)\n",
    "        \n",
    "    return train_history, test_history, model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "25c168ab-b064-4a76-a289-dee71ae1fdcd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Train the model and initiate a random vector W to start the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d5076bd4-d9c5-407e-9905-14b7f9dcca08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "wInit = np.random.uniform(0,1,809)\n",
    "\n",
    "ridge_results = GradientDescent_wReg(trainRDD, testRDD, wInit, nSteps = 10, reg_param = 0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "258d189e-820b-4707-80c9-1584957ae66c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Print final vector\n",
    "\n",
    "w = ridge_results[2][-1] # final model\n",
    "\n",
    "### Peform process in test data\n",
    "\n",
    "augmented_test_data = testRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "results = augmented_test_data.map(lambda x: (sigmoid(w.dot(x[0])),x[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5de36c91-eee5-4920-80f4-6f61ed752667",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set decision threshold to 0.5\n",
    "df_toy_predictions = pd.DataFrame(results)\n",
    "df_toy_predictions['pred'] = df_toy_predictions[0] >= .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2c35feeb-6e20-48a4-8acb-f18413de133d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create spark dataframe to write into blob\n",
    "df_toy_predictions = spark.createDataFrame(df_toy_predictions)\n",
    "df_toy_predictions.write.mode('overwrite').parquet(f\"{blob_url}/toy_model_results_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9b73222f-654b-4abc-8b2c-8d7ca5d4b461",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_toy_predictions = spark.read.parquet(f\"{blob_url}/toy_model_results_v3/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7e401218-79b5-4a33-a33f-7f0bc448029c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename \n",
    "\n",
    "df_toy_predictions = df_toy_predictions.withColumnRenamed('1', 'label')\n",
    "df_toy_predictions = df_toy_predictions.withColumnRenamed('pred', 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fce8e8c4-bc38-482d-b18a-0987cf17b086",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Sensitivity: 1.44%\n",
       "Specificity: 99.40%\n",
       "False positive rate: 0.60%\n",
       "False negative rate: 98.56%\n",
       "Recall: 1.44%\n",
       "Precision: 40.00%\n",
       "f1: 2.78%\n",
       "########### Confusion Matrix ###########\n",
       "                Predicted-delay  Predicted-on time\n",
       "Actual-delay                  2                137\n",
       "Actual-on time                3                493\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Sensitivity: 1.44%\nSpecificity: 99.40%\nFalse positive rate: 0.60%\nFalse negative rate: 98.56%\nRecall: 1.44%\nPrecision: 40.00%\nf1: 2.78%\n########### Confusion Matrix ###########\n                Predicted-delay  Predicted-on time\nActual-delay                  2                137\nActual-on time                3                493\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_results(df_toy_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8b9f8020-2180-4b6c-8dd1-45355a59c9a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here we observed the impact of limited data, as we are only using 0.01% of the full data. Therefore, our F1 Score is strongly affected by this as we see that we have a false negative rate of 98.56%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d9700f3a-b1e6-4bb8-bd1a-b7ec4b5ca919",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">              precision    recall  f1-score   support\n",
       "\n",
       "         0.0       0.78      0.99      0.88       496\n",
       "         1.0       0.40      0.01      0.03       139\n",
       "\n",
       "    accuracy                           0.78       635\n",
       "   macro avg       0.59      0.50      0.45       635\n",
       "weighted avg       0.70      0.78      0.69       635\n",
       "\n",
       "[[493   3]\n",
       " [137   2]]\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">              precision    recall  f1-score   support\n\n         0.0       0.78      0.99      0.88       496\n         1.0       0.40      0.01      0.03       139\n\n    accuracy                           0.78       635\n   macro avg       0.59      0.50      0.45       635\nweighted avg       0.70      0.78      0.69       635\n\n[[493   3]\n [137   2]]\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Evaluation with scikit learn\n",
    "\n",
    "y_true_lr = df_toy_predictions.select(['label']).collect()\n",
    "y_pred_lr = df_toy_predictions.select(['prediction']).collect()\n",
    "\n",
    "# Print metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true_lr, y_pred_lr))\n",
    "print(confusion_matrix(y_true_lr, y_pred_lr))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "W261_FA21_FINAL_PROJECT_TEAM11_NB9_Algorithm_Toy_Implementation",
   "notebookOrigID": 188115645377060,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
